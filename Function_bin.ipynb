{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporary notebook to collect up the functions that I'll use later when I make this official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os, sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import GetOldTweets3 as got\n",
    "\n",
    "def get_new_tweets(t_last_tweet,username = \"elonmusk\"):\n",
    "    \"\"\"Function to scrape the recent tweets of Elon Musk\"\"\"\n",
    "    #t_last_tweet must be pandas Timestamp data\n",
    "    os.makedirs('tweet_data', exist_ok=True)\n",
    "    date_str = str(t_last_tweet.date().year)+\"-\"\\\n",
    "              +str(t_last_tweet.date().month)+\"-\"\\\n",
    "              +str(t_last_tweet.date().day)\n",
    "    count = 0\n",
    "    # Creation of query object                                                                                                                                                                                      \n",
    "    tweetCriteria = got.manager.TweetCriteria().setUsername(username)\\\n",
    "                                               .setMaxTweets(count)\\\n",
    "                                               .setSince(date_str)\n",
    "    # Creation of list that contains all tweets                                                                                                                                                                     \n",
    "    tweets = None\n",
    "    for ntries in range(5):\n",
    "        try:\n",
    "            tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "        except SystemExit:\n",
    "            print(\"Trying again in 15 minutes.\")\n",
    "            time.sleep(15*60)\n",
    "        else:\n",
    "            break\n",
    "    if tweets is None:\n",
    "        print(\"Failed after 5 tries, quitting!\")\n",
    "        exit(1)\n",
    "\n",
    "    data = defaultdict(list)\n",
    "    for t in tweets:\n",
    "        data[\"username\"].append(username)\n",
    "        data[\"tweet_id\"].append(t.id)\n",
    "        data[\"reply_to\"].append(t.to)\n",
    "        data[\"date\"].append(t.date)\n",
    "        data[\"retweets\"].append(t.retweets)\n",
    "        data[\"favorites\"].append(t.favorites)\n",
    "        data[\"hashtags\"].append(list(set(t.hashtags.split())))\n",
    "        data[\"mentions\"].append(t.mentions)\n",
    "        data[\"text\"].append(t.text)\n",
    "        data[\"permalink\"].append(t.permalink)\n",
    "    if len(data) == 0: #no new tweets\n",
    "        return None\n",
    "    else:\n",
    "        #make a DataFrame out of the scraped tweets\n",
    "        df = pd.DataFrame(data, columns=[\"username\",\"tweet_id\",\"reply_to\",\"date\",\"retweets\",\"favorites\",\"hashtags\",\"mentions\",\"text\",\"permalink\"])        \n",
    "        # Convert 'Time' column to datetime and strip time information.\n",
    "        df['Time'] = pd.to_datetime(df['date'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def reload_tweet_data(username=\"elonmusk\"):\n",
    "   #note we'll have to do a .drop and set the 'Time' column to the proper values every time\n",
    "    df = pd.read_csv('./tweet_data/'+username+'.csv').drop(['Unnamed: 0'],axis='columns')\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_hashtag(text): #renders a hastag into plain text for NLP\n",
    "    txt_list = re.findall('[A-Z][^A-Z]*', text)\n",
    "    return map(lambda x:x.lower(),\" \".join(txt_list)) \n",
    "\n",
    "def standardize_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"RT\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^A-Za-z0-9(),:;!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('vader_lexicon') #get the bloody lexicon\n",
    "sid = SentimentIntensityAnalyzer() #returns error if no lexicon\n",
    "def tweet_word_count(df)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') #split on words\n",
    "    df[\"tokens\"] = df[\"tweet\"].apply(tokenizer.tokenize) #returns list of individual words\n",
    "    df['tweet_length'] = df.apply(lambda row : len(row['tokens']), axis=1) #creates tweet length column\n",
    "    df.drop(['tokens'],axis='columns')\n",
    "    \n",
    "    \n",
    "def construct_features(tweets):\n",
    "    \"\"\"Constructs features from Elon's tweet data\"\"\"\n",
    "    tweets = standardize_text(tweets,\"tweet\")\n",
    "    tweets[\"hashtags\"] = tweetsconvert_hastag()\n",
    "    #Make a rate of sentiment change feature\n",
    "tweets_clean_df['dSentiment_dTime'] = (tweets_clean_df['Sentiment']-tweets_clean_df['Sentiment'].shift(-1)).fillna(0.)/(tweets_clean_df['delta_Time'])\n",
    "tweets_clean_df['dSentiment_dTweet'] = (tweets_clean_df['Sentiment']-tweets_clean_df['Sentiment'].shift(-1)).fillna(0.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
